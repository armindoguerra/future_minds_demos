{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6b277-c2f8-4f78-8890-39a1e0f1feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0f9783-5673-4558-bb54-60532fdffe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install watermark\n",
    "# !pip install langchain-community langchain-core\n",
    "# !pip install -U langchain-openai\n",
    "# !pip install -U weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43355a4-5b06-48e5-8a21-8e7b83ce6de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from credentials import OPENAI_API_KEY\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db374f10-a5df-4089-84b1-520ea76f7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Armindo Guerra\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Armindo Guerra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e9bf8d-6bba-4756-b13a-96a2aafe3c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain_core  : 0.3.47\n",
      "langchain_openai: 0.3.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab19b99-dd6d-4fff-9222-879352ee8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3d3fa7-2109-449b-95f6-077b10622704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Message:  Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  how are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Message:  I'm just a program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  do you know my name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Message:  No, I don't have access to personal information unless you provide it during our conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  exit\n"
     ]
    }
   ],
   "source": [
    "# Define System Prompt\n",
    "system_prompt = SystemMessage(\"You are a helpful AI Assistant. Answer the User's queries succinctly in one sentence.\")\n",
    "\n",
    "# Start Storage for Historical Message History\n",
    "messages = [system_prompt]\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Get User's Message\n",
    "    user_message = HumanMessage(input(\"\\nUser: \"))\n",
    "    \n",
    "    if user_message.content.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        # Extend Messages List With User Message\n",
    "        messages.append(user_message)\n",
    "\n",
    "    # Pass Entire Message Sequence to LLM to Generate Response\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    print(\"\\nAI Message: \", response.content)\n",
    "\n",
    "    # Add AI's Response to Message List\n",
    "    messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380b3302-cd69-4e4a-9b44-eaf3209394bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: hello\n",
      "AI: Hello! How can I assist you today?\n",
      "HUMAN: how are you?\n",
      "AI: I'm just a program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\n",
      "HUMAN: do you know my name?\n",
      "AI: No, I don't have access to personal information unless you provide it during our conversation.\n"
     ]
    }
   ],
   "source": [
    "def format_conversation(messages):\n",
    "    \n",
    "    # Create an empty list placeholder\n",
    "    conversation = []\n",
    "    \n",
    "    # Start from index 1 to skip the first system message\n",
    "    for message in messages[1:]:\n",
    "        conversation.append(f\"{message.type.upper()}: {message.content}\")\n",
    "    \n",
    "    # Join with newlines\n",
    "    return \"\\n\".join(conversation)\n",
    "    # return conversation\n",
    "\n",
    "conversation = format_conversation(messages)\n",
    "\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94230d38-fa59-4201-ad9f-9c5a0c1eee13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
